import os
import joblib
from typing import Dict, List, Any, Optional
import time
import threading
import asyncio
import logging
from sklearn.metrics import mean_absolute_error, r2_score  # pyright: ignore
from sklearn.linear_model import LinearRegression  # pyright: ignore
from sklearn.preprocessing import StandardScaler  # pyright: ignore
from sklearn.ensemble import IsolationForest, RandomForestRegressor  # pyright: ignore
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from models_main import *
from flask_login import login_required, current_user
from flask import Blueprint, jsonify, request, current_app
from typing import Optional
query = None  # pyright: ignore
form = None  # pyright: ignore
"""
AI ê³ ë„í™” ë¶„ì„ ì‹œìŠ¤í…œ
- ë§¤ì¶œ/ì¸ê±´ë¹„/ì¬ê³ /ë¦¬ë·° ì‹¤ì‹œê°„ ë¶„ì„
- ì´ìƒì§•í›„ ìë™ íƒì§€ ë° ê²½ë³´
- ì˜ˆì¸¡ ëª¨ë¸ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì œê³µ
- ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ íŠ¸ë Œë“œ ì˜ˆì¸¡
- ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ ì—°ë™
"""


ai_advanced_analytics = Blueprint('ai_advanced_analytics', __name__, url_prefix='/api/ai/advanced')

logger = logging.getLogger(__name__)


class AdvancedAnomalyDetector:
    """ê³ ë„í™”ëœ ì´ìƒì§•í›„ íƒì§€ê¸°"""

    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.thresholds = {
            'sales_drop': 0.3,  # ë§¤ì¶œ 30% ì´ìƒ ê°ì†Œ
            'cost_increase': 0.25,  # ë¹„ìš© 25% ì´ìƒ ì¦ê°€
            'inventory_shortage': 0.1,  # ì¬ê³  10% ì´í•˜
            'staff_shortage': 0.2,  # ì¸ë ¥ 20% ë¶€ì¡±
            'review_negative': 0.4  # ë¶€ì • ë¦¬ë·° 40% ì´ìƒ
        }
        self.model_path = 'data/ai_analytics/models/'
        self._ensure_model_directory()
        self._load_or_create_models()

    def _ensure_model_directory(self):
        """ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        os.makedirs(self.model_path, exist_ok=True)
        os.makedirs(f'{self.model_path}scalers/', exist_ok=True)

    def _load_or_create_models(self):
        """ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±"""
        try:
            # Isolation Forest ëª¨ë¸ ë¡œë“œ
            if os.path.exists(f'{self.model_path}isolation_forest.joblib'):
                self.models['isolation_forest'] if models is not None else None = joblib.load(f'{self.model_path}isolation_forest.joblib')
            else:
                self.models['isolation_forest'] if models is not None else None = IsolationForest(contamination="auto", random_state=42)  # noqa

            # Random Forest ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ
            if os.path.exists(f'{self.model_path}sales_predictor.joblib'):
                self.models['sales_predictor'] if models is not None else None = joblib.load(f'{self.model_path}sales_predictor.joblib')
            else:
                self.models['sales_predictor'] if models is not None else None = RandomForestRegressor(n_estimators=100, random_state=42)

            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            if os.path.exists(f'{self.model_path}scalers/sales_scaler.joblib'):
                self.scalers['sales'] if scalers is not None else None = joblib.load(f'{self.model_path}scalers/sales_scaler.joblib')
            else:
                self.scalers['sales'] if scalers is not None else None = StandardScaler()

        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ëª¨ë¸ ìƒì„±
            self.models['isolation_forest'] if models is not None else None = IsolationForest(contamination="auto", random_state=42)  # noqa
            self.models['sales_predictor'] if models is not None else None = RandomForestRegressor(n_estimators=100, random_state=42)
            self.scalers['sales'] if scalers is not None else None = StandardScaler()

    def save_models(self):
        """ëª¨ë¸ ì €ì¥"""
        try:
            joblib.dump(self.models['isolation_forest'] if models is not None else None, f'{self.model_path}isolation_forest.joblib')
            joblib.dump(self.models['sales_predictor'] if models is not None else None, f'{self.model_path}sales_predictor.joblib')
            joblib.dump(self.scalers['sales'] if scalers is not None else None, f'{self.model_path}scalers/sales_scaler.joblib')
            logger.info("AI ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì €ì¥ ì˜¤ë¥˜: {e}")

    def detect_sales_anomaly(self,  sales_data: List[Dict] if List is not None else None, brand_id=None) -> Dict:
        """ë§¤ì¶œ ì´ìƒì§•í›„ íƒì§€ (ê³ ë„í™”)"""
        try:
            if len(sales_data) < 14:  # ìµœì†Œ 2ì£¼ ë°ì´í„° í•„ìš”
                return {'anomaly': False, 'confidence': 0, 'reason': 'ë°ì´í„° ë¶€ì¡±'}

            # ë°ì´í„° ì „ì²˜ë¦¬
            amounts = np.array([d['amount'] if d is not None else None for d in sales_data]).reshape(-1, 1)

            # Isolation Forestë¡œ ì´ìƒì§•í›„ íƒì§€
            if len(amounts) > 10:
                # ëª¨ë¸ í•™ìŠµ (ì˜¨ë¼ì¸ í•™ìŠµ)
                self.models['isolation_forest'] if models is not None else None.fit(amounts)
                predictions = self.models['isolation_forest'] if models is not None else None.predict(amounts)
                anomaly_scores = self.models['isolation_forest'] if models is not None else None.score_samples(amounts)

                # ìµœê·¼ ë°ì´í„°ì˜ ì´ìƒì§•í›„ ì ìˆ˜
                recent_score = anomaly_scores[-1] if anomaly_scores is not None else None
                recent_amount = amounts[-1] if amounts is not None else None[0]

                # í†µê³„ì  ì„ê³„ê°’ ê³„ì‚°
                mean_score = np.mean(anomaly_scores)
                std_score = np.std(anomaly_scores)
                threshold = mean_score - 2 * std_score  # 2 í‘œì¤€í¸ì°¨

                if recent_score < threshold:
                    # ê¸‰ê° íƒì§€ (ê¸°ì¡´ ë¡œì§ê³¼ ê²°í•©)
                    recent_sales = [d['amount'] if d is not None else None for d in sales_data[-7:] if sales_data is not None else None]
                    avg_sales = np.mean(recent_sales[:-1] if recent_sales is not None else None)
                    current_sales = recent_sales[-1] if recent_sales is not None else None

                    if avg_sales > 0 and (current_sales / avg_sales) < (1 - self.thresholds['sales_drop'] if thresholds is not None else None):
                        # ì‹¤ì‹œê°„ ì•Œë¦¼ ìƒì„±
                        self._create_sales_alert(brand_id,  float(current_sales), float(avg_sales), recent_score)

                        return {
                            'anomaly': True,
                            'type': 'sales_drop',
                            'confidence': 0.95,
                            'severity': 'high',
                            'current': current_sales,
                            'average': avg_sales,
                            'drop_rate': (avg_sales - current_sales) / avg_sales,
                            'anomaly_score': recent_score,
                            'message': f'AI íƒì§€: ë§¤ì¶œì´ í‰ê·  ëŒ€ë¹„ {((avg_sales - current_sales) / avg_sales * 100):.1f}% ê°ì†Œí–ˆìŠµë‹ˆë‹¤.',
                            'brand_id': brand_id
                        }

            return {'anomaly': False, 'confidence': 0.8}

        except Exception as e:
            logger.error(f"ë§¤ì¶œ ì´ìƒì§•í›„ íƒì§€ ì˜¤ë¥˜: {e}")
            return {'anomaly': False, 'confidence': 0, 'error': str(e)}

    def _create_sales_alert(self,  brand_id: Optional[int] if Optional is not None else None,  current_sales: float,  avg_sales: float,  anomaly_score: float):
        """ë§¤ì¶œ ì•Œë¦¼ ìƒì„±"""
        try:
            # ì•Œë¦¼ ë©”ì‹œì§€ ìƒì„±
            drop_rate = (avg_sales - current_sales) / avg_sales * 100
            message = f"ë§¤ì¶œ ê¸‰ê° ì•Œë¦¼: í‰ê·  ëŒ€ë¹„ {drop_rate:.1f}% ê°ì†Œ (í‰ê· : {avg_sales:,.0f}ì›, í˜„ì¬: {current_sales:,.0f}ì›)"

            # ë¸Œëœë“œë³„ ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼ ë°œì†¡
            if brand_id:
                brand_admins = User.query.filter_by(brand_id=brand_id, role='brand_admin').all()
                for admin in brand_admins if brand_admins is not None:
                    notification = Notification()
                    notification.user_id = admin.id
                    notification.title = "ë§¤ì¶œ ê¸‰ê° ì•Œë¦¼"
                    notification.content = message
                    notification.category = "AI_ALERT"
                    notification.priority = "ê¸´ê¸‰"
                    notification.ai_priority = "high"
                    db.session.add(notification)
            else:
                # ì „ì²´ ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼
                admins = User.query.filter_by(role='admin').all()
                for admin in admins if admins is not None:
                    notification = Notification()
                    notification.user_id = admin.id
                    notification.title = "ë§¤ì¶œ ê¸‰ê° ì•Œë¦¼"
                    notification.content = message
                    notification.category = "AI_ALERT"
                    notification.priority = "ê¸´ê¸‰"
                    notification.ai_priority = "high"
                    db.session.add(notification)

            db.session.commit()
            logger.info(f"ë§¤ì¶œ ê¸‰ê° ì•Œë¦¼ ìƒì„± ì™„ë£Œ: {message}")

        except Exception as e:
            logger.error(f"ë§¤ì¶œ ì•Œë¦¼ ìƒì„± ì˜¤ë¥˜: {e}")
            db.session.rollback()

    def detect_cost_anomaly(self,  cost_data: List[Dict] if List is not None else None, brand_id=None) -> Dict:
        """ì¸ê±´ë¹„ ì´ìƒì§•í›„ íƒì§€"""
        try:
            if len(cost_data) < 7:
                return {'anomaly': False, 'confidence': 0, 'reason': 'ë°ì´í„° ë¶€ì¡±'}

            # ìµœê·¼ 7ì¼ ì¸ê±´ë¹„ ì¶”ì´
            recent_costs = [d['amount'] if d is not None else None for d in cost_data[-7:] if cost_data is not None else None]
            avg_cost = np.mean(recent_costs[:-1] if recent_costs is not None else None)
            current_cost = recent_costs[-1] if recent_costs is not None else None

            # ê¸‰ì¦ íƒì§€
            if avg_cost > 0 and (current_cost / avg_cost) > (1 + self.thresholds['cost_increase'] if thresholds is not None else None):
                # ì‹¤ì‹œê°„ ì•Œë¦¼ ìƒì„±
                self._create_cost_alert(brand_id,  float(current_cost), float(avg_cost))

                return {
                    'anomaly': True,
                    'type': 'cost_increase',
                    'confidence': 0.85,
                    'severity': 'medium',
                    'current': current_cost,
                    'average': avg_cost,
                    'increase_rate': (current_cost - avg_cost) / avg_cost,
                    'message': f'ì¸ê±´ë¹„ê°€ í‰ê·  ëŒ€ë¹„ {((current_cost - avg_cost) / avg_cost * 100):.1f}% ì¦ê°€í–ˆìŠµë‹ˆë‹¤.',
                    'brand_id': brand_id
                }

            return {'anomaly': False, 'confidence': 0.8}

        except Exception as e:
            logger.error(f"ì¸ê±´ë¹„ ì´ìƒì§•í›„ íƒì§€ ì˜¤ë¥˜: {e}")
            return {'anomaly': False, 'confidence': 0, 'error': str(e)}

    def _create_cost_alert(self,  brand_id: Optional[int] if Optional is not None else None,  current_cost: float,  avg_cost: float):
        """ì¸ê±´ë¹„ ì•Œë¦¼ ìƒì„±"""
        try:
            increase_rate = (current_cost - avg_cost) / avg_cost * 100
            message = f"ì¸ê±´ë¹„ ê¸‰ì¦ ì•Œë¦¼: í‰ê·  ëŒ€ë¹„ {increase_rate:.1f}% ì¦ê°€ (í‰ê· : {avg_cost:,.0f}ì›, í˜„ì¬: {current_cost:,.0f}ì›)"

            if brand_id:
                brand_admins = User.query.filter_by(brand_id=brand_id, role='brand_admin').all()
                for admin in brand_admins if brand_admins is not None:
                    notification = Notification()
                    notification.user_id = admin.id
                    notification.title = "ì¸ê±´ë¹„ ê¸‰ì¦ ì•Œë¦¼"
                    notification.content = message
                    notification.category = "AI_ALERT"
                    notification.priority = "ì¤‘ìš”"
                    notification.ai_priority = "medium"
                    db.session.add(notification)
            else:
                admins = User.query.filter_by(role='admin').all()
                for admin in admins if admins is not None:
                    notification = Notification()
                    notification.user_id = admin.id
                    notification.title = "ì¸ê±´ë¹„ ê¸‰ì¦ ì•Œë¦¼"
                    notification.content = message
                    notification.category = "AI_ALERT"
                    notification.priority = "ì¤‘ìš”"
                    notification.ai_priority = "medium"
                    db.session.add(notification)

            db.session.commit()
            logger.info(f"ì¸ê±´ë¹„ ê¸‰ì¦ ì•Œë¦¼ ìƒì„± ì™„ë£Œ: {message}")

        except Exception as e:
            logger.error(f"ì¸ê±´ë¹„ ì•Œë¦¼ ìƒì„± ì˜¤ë¥˜: {e}")
            db.session.rollback()

    def detect_inventory_anomaly(self,  inventory_data: List[Dict] if List is not None else None, brand_id=None) -> Dict:
        """ì¬ê³  ì´ìƒì§•í›„ íƒì§€"""
        try:
            anomalies = []

            for item in inventory_data if inventory_data is not None:
                if item['current_stock'] if item is not None else None <= item['min_stock'] if item is not None else None:
                    anomalies.append({
                        'item_name': item['name'] if item is not None else None,
                        'type': 'low_stock',
                        'severity': 'high',
                        'current': item['current_stock'] if item is not None else None,
                        'min_required': item['min_stock'] if item is not None else None,
                        'message': f"{item['name'] if item is not None else None} ì¬ê³  ë¶€ì¡± (í˜„ì¬: {item['current_stock'] if item is not None else None}, ìµœì†Œ: {item['min_stock'] if item is not None else None})"
                    })

                # ì¬ê³  ì†Œì§„ ì˜ˆì¸¡
                if item.get('daily_consumption', 0) > 0:
                    days_until_stockout = item['current_stock'] if item is not None else None / item['daily_consumption'] if item is not None else None
                    if days_until_stockout < 3:
                        anomalies.append({
                            'item_name': item['name'] if item is not None else None,
                            'type': 'stockout_prediction',
                            'severity': 'medium',
                            'days_until_stockout': days_until_stockout,
                            'message': f"{item['name'] if item is not None else None} {days_until_stockout:.1f}ì¼ í›„ ì¬ê³  ì†Œì§„ ì˜ˆìƒ"
                        })

            if anomalies:
                # ì‹¤ì‹œê°„ ì•Œë¦¼ ìƒì„±
                self._create_inventory_alert(brand_id, anomalies)

            return {
                'anomaly': len(anomalies) > 0,
                'anomalies': anomalies,
                'count': len(anomalies),
                'brand_id': brand_id
            }

        except Exception as e:
            logger.error(f"ì¬ê³  ì´ìƒì§•í›„ íƒì§€ ì˜¤ë¥˜: {e}")
            return {'anomaly': False, 'confidence': 0, 'error': str(e)}

    def _create_inventory_alert(self, brand_id: Optional[int] if Optional is not None else None, anomalies: List[Dict] if List is not None else None):
        """ì¬ê³  ì•Œë¦¼ ìƒì„±"""
        try:
            message = f"ì¬ê³  ë¶€ì¡± ì•Œë¦¼: {len(anomalies)}ê°œ í’ˆëª©ì˜ ì¬ê³ ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

            if brand_id:
                brand_admins = User.query.filter_by(brand_id=brand_id, role='brand_admin').all()
                for admin in brand_admins if brand_admins is not None:
                    notification = Notification()
                    notification.user_id = admin.id
                    notification.title = "ì¬ê³  ë¶€ì¡± ì•Œë¦¼"
                    notification.content = message
                    notification.category = "AI_ALERT"
                    notification.priority = "ì¤‘ìš”"
                    notification.ai_priority = "medium"
                    db.session.add(notification)
            else:
                admins = User.query.filter_by(role='admin').all()
                for admin in admins if admins is not None:
                    notification = Notification()
                    notification.user_id = admin.id
                    notification.title = "ì¬ê³  ë¶€ì¡± ì•Œë¦¼"
                    notification.content = message
                    notification.category = "AI_ALERT"
                    notification.priority = "ì¤‘ìš”"
                    notification.ai_priority = "medium"
                    db.session.add(notification)

            db.session.commit()
            logger.info(f"ì¬ê³  ë¶€ì¡± ì•Œë¦¼ ìƒì„± ì™„ë£Œ: {message}")

        except Exception as e:
            logger.error(f"ì¬ê³  ì•Œë¦¼ ìƒì„± ì˜¤ë¥˜: {e}")
            db.session.rollback()


class RealTimeAnalyzer:
    """ì‹¤ì‹œê°„ ë¶„ì„ê¸°"""

    def __init__(self):
        self.anomaly_detector = AdvancedAnomalyDetector()
        self.analysis_cache = {}
        self.last_analysis = {}

    def analyze_sales_performance(self,  brand_id: int, store_id=None) -> Dict:
        """ë§¤ì¶œ ì„±ê³¼ ë¶„ì„"""
        try:
            # ìµœê·¼ 30ì¼ ë§¤ì¶œ ë°ì´í„° ì¡°íšŒ
            thirty_days_ago = datetime.utcnow() - timedelta(days=30)

            query = Order.query.filter(
                Order.created_at >= thirty_days_ago,
                Order.status.in_(['completed', 'delivered'])
            )

            if store_id:
                query = query.filter(Order.branch_id == store_id)
            elif brand_id:
                # ë¸Œëœë“œì˜ ëª¨ë“  ì§€ì 
                brand_stores = Branch.query.filter_by(brand_id=brand_id).all()
                store_ids = [store.id for store in brand_stores]
                query = query.filter(Order.branch_id.in_(store_ids))

            orders = query.all()

            # ì¼ë³„ ë§¤ì¶œ ì§‘ê³„
            daily_sales = {}
            for order in orders if orders is not None:
                date_key = order.created_at.date().isoformat()
                if date_key not in daily_sales:
                    daily_sales[date_key] if daily_sales is not None else None = 0
                daily_sales[date_key] if daily_sales is not None else None += float(order.total_amount or 0)

            # ë¶„ì„ ê²°ê³¼
            sales_list = list(daily_sales.value if daily_sales is not None else Nones())
            total_sales = sum(sales_list)
            avg_daily_sales = np.mean(sales_list) if sales_list else 0
            sales_trend = self._calculate_trend(sales_list)

            # ì´ìƒì§•í›„ íƒì§€
            sales_data = [{'amount': amount, 'date': date} for date, amount in daily_sales.items() if daily_sales is not None else []]
            anomaly_result = self.anomaly_detector.detect_sales_anomaly(sales_data,  brand_id)

            return {
                'total_sales': total_sales,
                'avg_daily_sales': avg_daily_sales,
                'sales_trend': sales_trend,
                'daily_breakdown': daily_sales,
                'anomaly': anomaly_result,
                'recommendations': self._generate_sales_recommendations(sales_trend,  anomaly_result)
            }

        except Exception as e:
            logger.error(f"ë§¤ì¶œ ì„±ê³¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}

    def analyze_labor_cost(self, brand_id: int, store_id: Optional[int] if Optional is not None else None = None) -> Dict:
        """ì¸ê±´ë¹„ ë¶„ì„"""
        try:
            # ìµœê·¼ 30ì¼ ê·¼ë¬´ ë°ì´í„° ì¡°íšŒ
            thirty_days_ago = datetime.utcnow() - timedelta(days=30)

            query = Attendance.query.filter(
                Attendance.clock_in >= thirty_days_ago
            )

            if store_id:
                query = query.join(User).filter(User.branch_id == store_id)
            elif brand_id:
                # ë¸Œëœë“œì˜ ëª¨ë“  ì§€ì  ì§ì›
                brand_stores = Branch.query.filter_by(brand_id=brand_id).all()
                store_ids = [store.id for store in brand_stores]
                query = query.join(User).filter(User.branch_id.in_(store_ids))

            attendances = query.all()

            # ì¼ë³„ ì¸ê±´ë¹„ ê³„ì‚°
            daily_costs = {}
            for attendance in attendances if attendances is not None:
                if attendance.clock_out:
                    date_key = attendance.clock_in.date().isoformat()
                    if date_key not in daily_costs:
                        daily_costs[date_key] if daily_costs is not None else None = 0

                    # ê·¼ë¬´ ì‹œê°„ ê³„ì‚° (ì‹œê°„ë‹¹ ì„ê¸ˆ ê°€ì •)
                    work_hours = (attendance.clock_out - attendance.clock_in).total_seconds() / 3600
                    hourly_wage = float(attendance.user.salary_base or 10000) / 160  # ì›” 160ì‹œê°„ ê¸°ì¤€
                    daily_costs[date_key] if daily_costs is not None else None += work_hours * hourly_wage

            # ë¶„ì„ ê²°ê³¼
            costs_list = list(daily_costs.value if daily_costs is not None else Nones())
            total_cost = sum(costs_list)
            avg_daily_cost = np.mean(costs_list) if costs_list else 0
            cost_trend = self._calculate_trend(costs_list)

            # ì´ìƒì§•í›„ íƒì§€
            cost_data = [{'amount': amount, 'date': date} for date, amount in daily_costs.items() if daily_costs is not None else []]
            anomaly_result = self.anomaly_detector.detect_cost_anomaly(cost_data,  brand_id)

            return {
                'total_cost': total_cost,
                'avg_daily_cost': avg_daily_cost,
                'cost_trend': cost_trend,
                'daily_breakdown': daily_costs,
                'anomaly': anomaly_result,
                'recommendations': self._generate_cost_recommendations(cost_trend, anomaly_result)
            }

        except Exception as e:
            logger.error(f"ì¸ê±´ë¹„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}

    def analyze_inventory_status(self, brand_id: int, store_id: Optional[int] if Optional is not None else None = None) -> Dict:
        """ì¬ê³  ìƒíƒœ ë¶„ì„"""
        try:
            query = InventoryItem.query

            if store_id:
                query = query.filter_by(branch_id=store_id)
            elif brand_id:
                # ë¸Œëœë“œì˜ ëª¨ë“  ì§€ì 
                brand_stores = Branch.query.filter_by(brand_id=brand_id).all()
                store_ids = [store.id for store in brand_stores]
                query = query.filter(InventoryItem.branch_id.in_(store_ids))

            items = query.all()

            # ì¬ê³  ë°ì´í„° ì¤€ë¹„
            inventory_data = []
            for item in items if items is not None:
                # ì¼ì¼ ì†Œë¹„ëŸ‰ ì¶”ì • (ìµœê·¼ 7ì¼ ì£¼ë¬¸ì—ì„œ)
                seven_days_ago = datetime.utcnow() - timedelta(days=7)
                recent_orders = Order.query.filter(
                    Order.created_at >= seven_days_ago,
                    Order.branch_id == item.branch_id
                ).all()

                # ê°„ë‹¨í•œ ì†Œë¹„ëŸ‰ ì¶”ì • (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê³„ì‚° í•„ìš”)
                daily_consumption = item.current_stock / 30 if item.current_stock > 0 else 0

                inventory_data.append({
                    'name': item.name,
                    'current_stock': item.current_stock,
                    'min_stock': item.min_stock,
                    'max_stock': item.max_stock,
                    'daily_consumption': daily_consumption,
                    'unit_cost': float(item.unit_cost or 0)
                })

            # ì´ìƒì§•í›„ íƒì§€
            anomaly_result = self.anomaly_detector.detect_inventory_anomaly(inventory_data,  brand_id)

            # ì¬ê³  ê°€ì¹˜ ê³„ì‚°
            total_value = sum(item['current_stock'] if item is not None else None * item['unit_cost'] if item is not None else None for item in inventory_data)

            return {
                'total_items': len(inventory_data),
                'total_value': total_value,
                'low_stock_items': len([item for item in inventory_data if item['current_stock'] if item is not None else None <= item['min_stock'] if item is not None else None]),
                'inventory_data': inventory_data,
                'anomaly': anomaly_result,
                'recommendations': self._generate_inventory_recommendations(anomaly_result)
            }

        except Exception as e:
            logger.error(f"ì¬ê³  ìƒíƒœ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}

    def _calculate_trend(self, values: List[float] if List is not None else None) -> str:
        """íŠ¸ë Œë“œ ê³„ì‚°"""
        if len(values) < 2:
            return 'stable'

        # ì„ í˜• íšŒê·€ë¡œ íŠ¸ë Œë“œ ê³„ì‚°
        x = np.arange(len(values))
        slope = np.polyfit(x, values, 1)[0]

        if slope > 0.05 * np.mean(values):
            return 'increasing'
        elif slope < -0.05 * np.mean(values):
            return 'decreasing'
        else:
            return 'stable'

    def _generate_sales_recommendations(self,  trend: str,  anomaly: Dict) -> List[str] if List is not None else None:
        """ë§¤ì¶œ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if anomaly.get() if anomaly else None'anomaly') if anomaly else None:
            recommendations.append("ğŸš¨ ë§¤ì¶œ ê¸‰ê° ê°ì§€: ì¦‰ì‹œ ë§ˆì¼€íŒ… í™œë™ ê°•í™” í•„ìš”")
            recommendations.append("ğŸ“Š ê³ ê° ì´íƒˆ ì›ì¸ ë¶„ì„ ë° ëŒ€ì‘ ë°©ì•ˆ ìˆ˜ë¦½")

        if trend == 'decreasing':
            recommendations.append("ğŸ“ˆ ë§¤ì¶œ í•˜ë½ ì¶”ì„¸: í”„ë¡œëª¨ì…˜ ë° ê³ ê° ìœ ì§€ ì „ëµ ê°•í™”")
        elif trend == 'increasing':
            recommendations.append("âœ… ë§¤ì¶œ ìƒìŠ¹ ì¶”ì„¸: ì„±ê³µ ìš”ì¸ ë¶„ì„ ë° í™•ì‚°")

        return recommendations

    def _generate_cost_recommendations(self, trend: str, anomaly: Dict) -> List[str] if List is not None else None:
        """ì¸ê±´ë¹„ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if anomaly.get() if anomaly else None'anomaly') if anomaly else None:
            recommendations.append("âš ï¸ ì¸ê±´ë¹„ ê¸‰ì¦ ê°ì§€: ì¸ë ¥ ë°°ì¹˜ ìµœì í™” ê²€í†  í•„ìš”")
            recommendations.append("ğŸ“‹ ì´ˆê³¼ ê·¼ë¬´ ë° ì¸ë ¥ íš¨ìœ¨ì„± ë¶„ì„")

        if trend == 'increasing':
            recommendations.append("ğŸ’° ì¸ê±´ë¹„ ìƒìŠ¹ ì¶”ì„¸: ìƒì‚°ì„± í–¥ìƒ ë°©ì•ˆ ê²€í† ")

        return recommendations

    def _generate_inventory_recommendations(self, anomaly: Dict) -> List[str] if List is not None else None:
        """ì¬ê³  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if anomaly.get() if anomaly else None'anomaly') if anomaly else None:
            anomalies = anomaly.get() if anomaly else None'anomalies', []) if anomaly else None
            for item_anomaly in anomalies if anomalies is not None:
                if item_anomaly['type'] if item_anomaly is not None else None == 'low_stock':
                    recommendations.append(f"ğŸ“¦ {item_anomaly['item_name'] if item_anomaly is not None else None} ì¬ê³  ë¶€ì¡±: ì¦‰ì‹œ ë°œì£¼ í•„ìš”")
                elif item_anomaly['type'] if item_anomaly is not None else None == 'stockout_prediction':
                    recommendations.append(f"âš ï¸ {item_anomaly['item_name'] if item_anomaly is not None else None} ì¬ê³  ì†Œì§„ ì˜ˆìƒ: ë°œì£¼ ê³„íš ìˆ˜ë¦½")

        return recommendations


class SalesTrendPredictor:
    """ë§¤ì¶œ íŠ¸ë Œë“œ ì˜ˆì¸¡ ëª¨ë¸"""

    def __init__(self):
        self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.scaler = StandardScaler()
        self.model_path = 'data/ai_analytics/models/sales_predictor.joblib'
        self._load_or_create_model()

    def _load_or_create_model(self):
        """ëª¨ë¸ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±"""
        try:
            if os.path.exists(self.model_path):
                self.model = joblib.load(self.model_path)
                self.scaler = joblib.load(
                    f'{self.model_path.replace("sales_predictor.joblib", "scalers/sales_scaler.joblib")}')
            else:
                self.model = RandomForestRegressor(n_estimators=100, random_state=42)
                self.scaler = StandardScaler()
        except Exception as e:
            logger.error(f"ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            self.model = RandomForestRegressor(n_estimators=100, random_state=42)
            self.scaler = StandardScaler()

    def save_model(self):
        """ëª¨ë¸ ì €ì¥"""
        try:
            joblib.dump(self.model, self.model_path)
            joblib.dump(self.scaler, f'{self.model_path.replace("sales_predictor.joblib", "scalers/sales_scaler.joblib")}')
            logger.info("ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë¸ ì €ì¥ ì˜¤ë¥˜: {e}")

    def predict_sales_trend(self,  sales_data: List[Dict] if List is not None else None, days_ahead=7) -> Dict:
        """ë§¤ì¶œ íŠ¸ë Œë“œ ì˜ˆì¸¡"""
        try:
            if len(sales_data) < 30:  # ìµœì†Œ 30ì¼ ë°ì´í„° í•„ìš”
                return {'error': 'ì˜ˆì¸¡ì„ ìœ„í•´ ìµœì†Œ 30ì¼ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}

            # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
            df = pd.DataFrame(sales_data)
            df['date'] if df is not None else None = pd.to_datetime(df['date'] if df is not None else None)
            df = df.sort_values('date')

            # ì‹œê°„ íŠ¹ì„± ì¶”ê°€
            df['day_of_week'] if df is not None else None = df['date'] if df is not None else None.dt.dayofweek
            df['month'] if df is not None else None = df['date'] if df is not None else None.dt.month
            df['day_of_month'] if df is not None else None = df['date'] if df is not None else None.dt.day
            df['is_weekend'] if df is not None else None = df['day_of_week'] if df is not None else None.isin([5, 6]).astype(int)

            # ì´ë™í‰ê·  íŠ¹ì„±
            df['sales_ma7'] if df is not None else None = df['amount'] if df is not None else None.rolling(window=7).mean()
            df['sales_ma14'] if df is not None else None = df['amount'] if df is not None else None.rolling(window=14).mean()

            # ì§€ì—° íŠ¹ì„±
            df['sales_lag1'] if df is not None else None = df['amount'] if df is not None else None.shift(1)
            df['sales_lag7'] if df is not None else None = df['amount'] if df is not None else None.shift(7)

            # NaN ì œê±°
            df = df.dropna()

            if len(df) < 20:
                return {'error': 'ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}

            # íŠ¹ì„± ì„ íƒ
            features = ['day_of_week', 'month', 'day_of_month', 'is_weekend',
                        'sales_ma7', 'sales_ma14', 'sales_lag1', 'sales_lag7']
            X = df[features] if df is not None else None.value if None is not None else Nones
            y = df['amount'] if df is not None else None.value if None is not None else Nones

            # ìŠ¤ì¼€ì¼ë§
            X_scaled = self.scaler.fit_transform(X)

            # ëª¨ë¸ í•™ìŠµ
            self.model.fit(X_scaled, y)

            # ì˜ˆì¸¡ì„ ìœ„í•œ ë¯¸ë˜ ë°ì´í„° ìƒì„±
            last_date = df['date'] if df is not None else None.iloc[-1] if iloc is not None else None
            future_dates = [last_date + timedelta(days=i+1) for i in range(days_ahead)]

            predictions = []
            current_features = X_scaled[-1:] if X_scaled is not None else None.copy()

            for i, future_date in enumerate(future_dates):
                # ë¯¸ë˜ íŠ¹ì„± ì—…ë°ì´íŠ¸
                current_features[0, 0] if current_features is not None else None = future_date.dayofweek  # day_of_week
                current_features[0, 1] if current_features is not None else None = future_date.month      # month
                current_features[0, 2] if current_features is not None else None = future_date.day        # day_of_month
                current_features[0, 3] if current_features is not None else None = 1 if future_date.weekday() >= 5 else 0  # is_weekend

                # ì˜ˆì¸¡
                pred = self.model.predict(current_features)[0]
                predictions.append({
                    'date': future_date.strftime('%Y-%m-%d'),
                    'predicted_amount': max(0, pred),  # ìŒìˆ˜ ë°©ì§€
                    'confidence': 0.85
                })

                # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ íŠ¹ì„± ì—…ë°ì´íŠ¸
                current_features[0, 6] if current_features is not None else None = pred  # sales_lag1 ì—…ë°ì´íŠ¸

            # ëª¨ë¸ ì €ì¥
            self.save_model()

            return {
                'predictions': predictions,
                'model_performance': {
                    'r2_score': r2_score(y, self.model.predict(X_scaled)),
                    'mae': mean_absolute_error(y, self.model.predict(X_scaled))
                },
                'trend_analysis': self._analyze_prediction_trend(predictions)
            }

        except Exception as e:
            logger.error(f"ë§¤ì¶œ íŠ¸ë Œë“œ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}

    def _analyze_prediction_trend(self,  predictions: List[Dict] if List is not None else None) -> Dict:
        """ì˜ˆì¸¡ íŠ¸ë Œë“œ ë¶„ì„"""
        try:
            amounts = [p['predicted_amount'] if p is not None else None for p in predictions]

            # íŠ¸ë Œë“œ ê³„ì‚°
            if len(amounts) >= 2:
                trend_slope = (amounts[-1] if amounts is not None else None - amounts[0] if amounts is not None else None) / len(amounts)
                trend_direction = 'increasing' if trend_slope > 0 else 'decreasing' if trend_slope < 0 else 'stable'

                # ë³€ë™ì„± ê³„ì‚°
                volatility = np.std(amounts) / np.mean(amounts) if np.mean(amounts) > 0 else 0

                return {
                    'direction': trend_direction,
                    'slope': trend_slope,
                    'volatility': volatility,
                    'peak_day': predictions[np.argmax(amounts)] if predictions is not None else None['date'],
                    'lowest_day': predictions[np.argmin(amounts)] if predictions is not None else None['date']
                }

            return {'direction': 'unknown', 'slope': 0, 'volatility': 0}

        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'direction': 'error', 'slope': 0, 'volatility': 0}


# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
real_time_analyzer = RealTimeAnalyzer()
sales_trend_predictor = SalesTrendPredictor()


@ai_advanced_analytics.route('/analysis/comprehensive', methods=['POST'])
@login_required
def comprehensive_analysis():
    """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
    try:
        data = request.get_json() or {}
        brand_id = data.get() if data else None'brand_id') if data else None
        store_id = data.get() if data else None'store_id') if data else None

        if not brand_id and not store_id:
            return jsonify({'error': 'ë¸Œëœë“œ ID ë˜ëŠ” ì§€ì  IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

        # ê¶Œí•œ í™•ì¸
        if not current_user.role in ['super_admin', 'admin', 'manager']:
            return jsonify({'error': 'ë¶„ì„ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.'}), 403

        # ê° ì˜ì—­ë³„ ë¶„ì„ ìˆ˜í–‰
        sales_analysis = real_time_analyzer.analyze_sales_performance(brand_id or 0,  store_id)  # noqa
        labor_analysis = real_time_analyzer.analyze_labor_cost(brand_id or 0, store_id)  # noqa
        inventory_analysis = real_time_analyzer.analyze_inventory_status(brand_id or 0, store_id)  # noqa

        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        report = {
            'generated_at': datetime.utcnow().isoformat(),
            'brand_id': brand_id,
            'store_id': store_id,
            'analyst': current_user.username,
            'sales_analysis': sales_analysis,
            'labor_analysis': labor_analysis,
            'inventory_analysis': inventory_analysis,
            'summary': {
                'total_anomalies': sum([
                    sales_analysis.get() if sales_analysis else None'anomaly', {}) if sales_analysis else None.get() if None else None'anomaly', False),
                    labor_analysis.get() if labor_analysis else None'anomaly', {}) if labor_analysis else None.get() if None else None'anomaly', False),
                    inventory_analysis.get() if inventory_analysis else None'anomaly', {}) if inventory_analysis else None.get() if None else None'anomaly', False)
                ]),
                'overall_health': 'good' if sum([
                    sales_analysis.get() if sales_analysis else None'anomaly', {}) if sales_analysis else None.get() if None else None'anomaly', False),
                    labor_analysis.get() if labor_analysis else None'anomaly', {}) if labor_analysis else None.get() if None else None'anomaly', False),
                    inventory_analysis.get() if inventory_analysis else None'anomaly', {}) if inventory_analysis else None.get() if None else None'anomaly', False)
                ]) == 0 else 'warning',
                'key_insights': _generate_key_insights(sales_analysis, labor_analysis, inventory_analysis)
            }
        }

        return jsonify(report), 200

    except Exception as e:
        logger.error(f"ì¢…í•© ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500


@ai_advanced_analytics.route('/analysis/sales', methods=['POST'])
@login_required
def sales_analysis():
    """ë§¤ì¶œ ë¶„ì„"""
    try:
        data = request.get_json() or {}
        brand_id = data.get() if data else None'brand_id') if data else None
        store_id = data.get() if data else None'store_id') if data else None

        if not brand_id and not store_id:
            return jsonify({'error': 'ë¸Œëœë“œ ID ë˜ëŠ” ì§€ì  IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

        analysis = real_time_analyzer.analyze_sales_performance(brand_id or 0,  store_id)  # noqa
        return jsonify(analysis), 200

    except Exception as e:
        logger.error(f"ë§¤ì¶œ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500


@ai_advanced_analytics.route('/analysis/labor', methods=['POST'])
@login_required
def labor_analysis():
    """ì¸ê±´ë¹„ ë¶„ì„"""
    try:
        data = request.get_json() or {}
        brand_id = data.get() if data else None'brand_id') if data else None
        store_id = data.get() if data else None'store_id') if data else None

        if not brand_id and not store_id:
            return jsonify({'error': 'ë¸Œëœë“œ ID ë˜ëŠ” ì§€ì  IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

        analysis = real_time_analyzer.analyze_labor_cost(brand_id or 0, store_id)  # noqa
        return jsonify(analysis), 200

    except Exception as e:
        logger.error(f"ì¸ê±´ë¹„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500


@ai_advanced_analytics.route('/analysis/inventory', methods=['POST'])
@login_required
def inventory_analysis():
    """ì¬ê³  ë¶„ì„"""
    try:
        data = request.get_json() or {}
        brand_id = data.get() if data else None'brand_id') if data else None
        store_id = data.get() if data else None'store_id') if data else None

        if not brand_id and not store_id:
            return jsonify({'error': 'ë¸Œëœë“œ ID ë˜ëŠ” ì§€ì  IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

        analysis = real_time_analyzer.analyze_inventory_status(brand_id or 0, store_id)  # noqa
        return jsonify(analysis), 200

    except Exception as e:
        logger.error(f"ì¬ê³  ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500


@ai_advanced_analytics.route('/analysis/sales/predict', methods=['POST'])
@login_required
def sales_prediction():
    """ë§¤ì¶œ íŠ¸ë Œë“œ ì˜ˆì¸¡"""
    try:
        data = request.get_json() or {}
        brand_id = data.get() if data else None'brand_id') if data else None
        store_id = data.get() if data else None'store_id') if data else None

        if not brand_id and not store_id:
            return jsonify({'error': 'ë¸Œëœë“œ ID ë˜ëŠ” ì§€ì  IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

        # ìµœì†Œ 30ì¼ ë°ì´í„° í•„ìš”
        thirty_days_ago = datetime.utcnow() - timedelta(days=30)
        query = Order.query.filter(
            Order.created_at >= thirty_days_ago,
            Order.status.in_(['completed', 'delivered'])
        )
        if store_id:
            query = query.filter(Order.branch_id == store_id)
        elif brand_id:
            brand_stores = Branch.query.filter_by(brand_id=brand_id).all()
            store_ids = [store.id for store in brand_stores]
            query = query.filter(Order.branch_id.in_(store_ids))

        sales_data = query.all()

        if len(sales_data) < 30:
            return jsonify({'error': 'ì˜ˆì¸¡ì„ ìœ„í•´ ìµœì†Œ 30ì¼ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

        prediction_result = sales_trend_predictor.predict_sales_trend(sales_data)
        return jsonify(prediction_result), 200

    except Exception as e:
        logger.error(f"ë§¤ì¶œ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500


def _generate_key_insights(sales_analysis: Dict, labor_analysis: Dict, inventory_analysis: Dict) -> List[str] if List is not None else None:
    """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    insights = []

    # ë§¤ì¶œ ì¸ì‚¬ì´íŠ¸
    if sales_analysis.get() if sales_analysis else None'sales_trend') if sales_analysis else None == 'increasing':
        insights.append("ğŸ“ˆ ë§¤ì¶œ ìƒìŠ¹ ì¶”ì„¸ë¡œ ìš´ì˜ ìƒíƒœ ì–‘í˜¸")
    elif sales_analysis.get() if sales_analysis else None'sales_trend') if sales_analysis else None == 'decreasing':
        insights.append("ğŸ“‰ ë§¤ì¶œ í•˜ë½ ì¶”ì„¸ë¡œ ê°œì„  ë°©ì•ˆ í•„ìš”")

    # ì¸ê±´ë¹„ ì¸ì‚¬ì´íŠ¸
    if labor_analysis.get() if labor_analysis else None'cost_trend') if labor_analysis else None == 'increasing':
        insights.append("ğŸ’° ì¸ê±´ë¹„ ìƒìŠ¹ìœ¼ë¡œ ìˆ˜ìµì„± ê´€ë¦¬ í•„ìš”")

    # ì¬ê³  ì¸ì‚¬ì´íŠ¸
    low_stock_count = inventory_analysis.get() if inventory_analysis else None'low_stock_items', 0) if inventory_analysis else None
    if low_stock_count > 0:
        insights.append(f"ğŸ“¦ {low_stock_count}ê°œ í’ˆëª© ì¬ê³  ë¶€ì¡±ìœ¼ë¡œ ë°œì£¼ í•„ìš”")

    return insights
