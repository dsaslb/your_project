#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Redis ì—†ì´ë„ ì‘ë™í•˜ëŠ” ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import requests
import time
import json
import statistics
from datetime import datetime
from typing import Dict, List, Any
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PerformanceTester:
    def __init__(self, base_url: str = "http://localhost:5000"):
        self.base_url = base_url
        self.results = {}

    def test_endpoint(
        self,
        endpoint: str,
        method: str = "GET",
        data: Dict = None,
        headers: Dict = None,
        iterations: int = 10,
    ) -> Dict[str, Any]:
        """ì—”ë“œí¬ì¸íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        url = f"{self.base_url}{endpoint}"
        response_times = []
        success_count = 0
        error_count = 0
        errors = []

        logger.info(f"í…ŒìŠ¤íŠ¸ ì¤‘: {method} {endpoint}")

        for i in range(iterations):
            try:
                start_time = time.time()

                if method.upper() == "GET":
                    response = requests.get(url, headers=headers, timeout=10)
                elif method.upper() == "POST":
                    response = requests.post(
                        url, json=data, headers=headers, timeout=10
                    )
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” HTTP ë©”ì„œë“œ: {method}")

                end_time = time.time()
                response_time = (end_time - start_time) * 1000  # msë¡œ ë³€í™˜

                if response.status_code < 400:
                    success_count += 1
                    response_times.append(response_time)
                else:
                    error_count += 1
                    errors.append(f"HTTP {response.status_code}: {response.text}")

            except requests.exceptions.Timeout:
                error_count += 1
                errors.append("Timeout (10ì´ˆ ì´ˆê³¼)")
            except Exception as e:
                error_count += 1
                errors.append(f"ì˜¤ë¥˜: {str(e)}")

        # í†µê³„ ê³„ì‚°
        if response_times:
            avg_time = statistics.mean(response_times)
            min_time = min(response_times)
            max_time = max(response_times)
            median_time = statistics.median(response_times)
        else:
            avg_time = min_time = max_time = median_time = 0

        result = {
            "endpoint": endpoint,
            "method": method,
            "iterations": iterations,
            "success_count": success_count,
            "error_count": error_count,
            "success_rate": (success_count / iterations) * 100,
            "response_times": {
                "average_ms": round(avg_time, 2),
                "min_ms": round(min_time, 2),
                "max_ms": round(max_time, 2),
                "median_ms": round(median_time, 2),
            },
            "performance_grade": self._grade_performance(avg_time),
            "errors": errors[:5],  # ìµœëŒ€ 5ê°œ ì˜¤ë¥˜ë§Œ í‘œì‹œ
        }

        return result

    def _grade_performance(self, avg_time_ms: float) -> str:
        """ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€"""
        if avg_time_ms < 500:
            return "A+ (ìš°ìˆ˜)"
        elif avg_time_ms < 1000:
            return "A (ì–‘í˜¸)"
        elif avg_time_ms < 2000:
            return "B (ë³´í†µ)"
        elif avg_time_ms < 5000:
            return "C (ëŠë¦¼)"
        else:
            return "D (ë§¤ìš° ëŠë¦¼)"

    def run_comprehensive_test(self) -> Dict[str, Any]:
        """ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("=== Your Program ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")

        test_cases = [
            {"endpoint": "/health", "method": "GET", "iterations": 20},
            {"endpoint": "/api/status", "method": "GET", "iterations": 15},
            {
                "endpoint": "/api/plugin-system/health",
                "method": "GET",
                "iterations": 10,
            },
            {"endpoint": "/api/performance/health", "method": "GET", "iterations": 10},
            {
                "endpoint": "/api/auth/login",
                "method": "POST",
                "data": {"username": "admin", "password": "admin123"},
                "iterations": 5,
            },
        ]

        results = []
        total_success = 0
        total_errors = 0
        all_response_times = []

        for test_case in test_cases:
            result = self.test_endpoint(**test_case)
            results.append(result)

            total_success += result["success_count"]
            total_errors += result["error_count"]
            all_response_times.extend(
                [r for r in result["response_times"].values() if r > 0]
            )

            # ê²°ê³¼ ì¶œë ¥
            logger.info(
                f"âœ… {result['endpoint']}: {result['performance_grade']} "
                f"(í‰ê· : {result['response_times']['average_ms']}ms)"
            )

        # ì „ì²´ í†µê³„
        overall_stats = {
            "timestamp": datetime.now().isoformat(),
            "total_tests": len(test_cases),
            "total_success": total_success,
            "total_errors": total_errors,
            "overall_success_rate": (
                (total_success / (total_success + total_errors)) * 100
                if (total_success + total_errors) > 0
                else 0
            ),
            "average_response_time": (
                round(statistics.mean(all_response_times), 2)
                if all_response_times
                else 0
            ),
            "max_response_time": max(all_response_times) if all_response_times else 0,
            "performance_issues": [],
        }

        # ì„±ëŠ¥ ì´ìŠˆ í™•ì¸
        for result in results:
            if result["response_times"]["average_ms"] > 2000:
                overall_stats["performance_issues"].append(
                    {
                        "endpoint": result["endpoint"],
                        "issue": f"ì‘ë‹µ ì‹œê°„ì´ 2ì´ˆ ì´ˆê³¼: {result['response_times']['average_ms']}ms",
                    }
                )

            if result["success_rate"] < 80:
                overall_stats["performance_issues"].append(
                    {
                        "endpoint": result["endpoint"],
                        "issue": f"ì„±ê³µë¥ ì´ ë‚®ìŒ: {result['success_rate']:.1f}%",
                    }
                )

        # ìµœì¢… ê²°ê³¼
        final_result = {
            "overall_stats": overall_stats,
            "detailed_results": results,
            "summary": self._generate_summary(overall_stats, results),
        }

        return final_result

    def _generate_summary(self, overall_stats: Dict, results: List[Dict]) -> str:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        summary = f"""
=== Your Program ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===
í…ŒìŠ¤íŠ¸ ì‹œê°„: {overall_stats['timestamp']}
ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {overall_stats['total_tests']}
ì „ì²´ ì„±ê³µë¥ : {overall_stats['overall_success_rate']:.1f}%
í‰ê·  ì‘ë‹µ ì‹œê°„: {overall_stats['average_response_time']}ms
ìµœëŒ€ ì‘ë‹µ ì‹œê°„: {overall_stats['max_response_time']}ms

ì„±ëŠ¥ ì´ìŠˆ: {len(overall_stats['performance_issues'])}ê°œ
"""

        if overall_stats["performance_issues"]:
            summary += "\nğŸš¨ ë°œê²¬ëœ ì„±ëŠ¥ ì´ìŠˆ:\n"
            for issue in overall_stats["performance_issues"]:
                summary += f"  - {issue['endpoint']}: {issue['issue']}\n"
        else:
            summary += "\nâœ… ì„±ëŠ¥ ì´ìŠˆ ì—†ìŒ\n"

        return summary


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = PerformanceTester()

    try:
        result = tester.run_comprehensive_test()

        # ê²°ê³¼ ì¶œë ¥
        print(result["summary"])

        # ìƒì„¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        with open("performance_test_results.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        print(
            f"\nğŸ“Š ìƒì„¸ ê²°ê³¼ê°€ 'performance_test_results.json' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        )

        # ì„±ëŠ¥ ë“±ê¸‰ë³„ ë¶„ë¥˜
        print("\nğŸ“ˆ ì—”ë“œí¬ì¸íŠ¸ë³„ ì„±ëŠ¥ ë“±ê¸‰:")
        for test_result in result["detailed_results"]:
            grade = test_result["performance_grade"]
            endpoint = test_result["endpoint"]
            avg_time = test_result["response_times"]["average_ms"]
            print(f"  {grade:<12} - {endpoint} ({avg_time}ms)")

    except Exception as e:
        logger.error(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
